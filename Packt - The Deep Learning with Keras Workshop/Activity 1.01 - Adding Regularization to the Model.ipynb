{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Regularization to the Model\n",
    "\n",
    "In this activity, we will utilize the same logistic regression model from the scikit-learn package. This time, however, we will add regularization to the model and search for the optimum regularization parameter â€” a process often called hyperparameter tuning. After training the models, we will test the predictions and compare the model evaluation metrics to those produced by the baseline model and the model without regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load in the feature and target datasets of the online shoppers purchasing intention dataset from '../data/OSI_feats_e3.csv' and '../data/OSI_target_e2.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(12330, 68)\n(12330, 1)\n"
    }
   ],
   "source": [
    "df_x = pd.read_csv(\"../data/OSI_feats_e3.csv\")\n",
    "df_y = pd.read_csv(\"../data/OSI_target_e2.csv\")\n",
    "print(df_x.shape)\n",
    "print(df_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create training and test datasets for each of the feature and target datasets. The training datasets will be used to train on, and the models will be evaluated using the test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(9864, 68)\n(2466, 68)\n(9864, 1)\n(2466, 1)\n"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=13)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Instantiate a model instance of the LogisticRegressionCV class of scikit-learn's linear_model package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n       1.e+06])"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "np.logspace(-2, 6, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.logspace(-2, 6, 9)\n",
    "\n",
    "model_l1 = LogisticRegressionCV(\n",
    "    Cs=Cs,\n",
    "    penalty='l1',\n",
    "    cv=10,\n",
    "    solver='liblinear',\n",
    "    max_iter=5000,\n",
    "    random_state=42,\n",
    ")\n",
    "model_l2 = LogisticRegressionCV(\n",
    "    Cs=Cs,\n",
    "    penalty='l2',\n",
    "    cv=10,\n",
    "    solver='lbfgs',\n",
    "    max_iter=5000,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegressionCV(Cs=array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n       1.e+06]),\n                     cv=10, max_iter=5000, random_state=42)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model_l1.fit(x_train, y_train['Revenue'])\n",
    "model_l2.fit(x_train, y_train['Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best hyperparameter for l1 regularization model: 10.0\nBest hyperparameter for l2 regularization model: 0.1\n"
    }
   ],
   "source": [
    "print(f'Best hyperparameter for l1 regularization model: {model_l1.C_[0]}')\n",
    "print(f'Best hyperparameter for l2 regularization model: {model_l2.C_[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Evaluate the models by comparing how they scored against the true values using the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_l1_pred = model_l1.predict(x_test)\n",
    "y_l2_pred = model_l2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8917274939172749\n0.8921330089213301\n"
    }
   ],
   "source": [
    "print(accuracy_score(y_pred=y_l1_pred, y_true=y_test))\n",
    "print(accuracy_score(y_pred=y_l2_pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7286432160804021\n0.40502793296089384\n0.5206463195691203\n"
    }
   ],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(\n",
    "    y_pred=y_l1_pred, \n",
    "    y_true=y_test,\n",
    "    average='binary'\n",
    ")\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.73\n0.40782122905027934\n0.5232974910394265\n"
    }
   ],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(\n",
    "    y_pred=y_l2_pred, \n",
    "    y_true=y_test,\n",
    "    average='binary'\n",
    ")\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(fscore)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37264bitdlwkvenvbec5b905c558415eb2dad3aba1eb0bd0",
   "display_name": "Python 3.7.2 64-bit ('dlwk': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}