{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600096248755",
   "display_name": "Python 3.7.2 64-bit ('dsw': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Speed Dating Dataset\n",
    "\n",
    "As an entrepreneur, you are planning to launch a new dating app into the market. The key feature that will differentiate your app from other competitors will be your high performing user-matching algorithm. Before building this model, you have partnered with a speed dating company to collect data from real events. You just received the dataset from your partner company but realized it is not as clean as you expected; there are missing and incorrect values. Your task is to fix the main data quality issues in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      iid    id  gender  idg  condtn  wave  round  position  positin1  order  \\\n0       1   1.0       0    1       1     1     10         7       NaN      4   \n1       1   1.0       0    1       1     1     10         7       NaN      3   \n2       1   1.0       0    1       1     1     10         7       NaN     10   \n3       1   1.0       0    1       1     1     10         7       NaN      5   \n4       1   1.0       0    1       1     1     10         7       NaN      7   \n...   ...   ...     ...  ...     ...   ...    ...       ...       ...    ...   \n8373  552  22.0       1   44       2    21     22        14      10.0      5   \n8374  552  22.0       1   44       2    21     22        13      10.0      4   \n8375  552  22.0       1   44       2    21     22        19      10.0     10   \n8376  552  22.0       1   44       2    21     22         3      10.0     16   \n8377  552   NaN       1   44       2    21     22         2      10.0     15   \n\n      ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  \\\n0     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n1     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n2     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n3     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n4     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n...   ...      ...      ...       ...     ...     ...      ...      ...   \n8373  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n8374  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n8375  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n8376  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n8377  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n\n      intel5_3  fun5_3  amb5_3  \n0          NaN     NaN     NaN  \n1          NaN     NaN     NaN  \n2          NaN     NaN     NaN  \n3          NaN     NaN     NaN  \n4          NaN     NaN     NaN  \n...        ...     ...     ...  \n8373       9.0     5.0     6.0  \n8374       9.0     5.0     6.0  \n8375       9.0     5.0     6.0  \n8376       9.0     5.0     6.0  \n8377       9.0     5.0     6.0  \n\n[8378 rows x 195 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>iid</th>\n      <th>id</th>\n      <th>gender</th>\n      <th>idg</th>\n      <th>condtn</th>\n      <th>wave</th>\n      <th>round</th>\n      <th>position</th>\n      <th>positin1</th>\n      <th>order</th>\n      <th>...</th>\n      <th>attr3_3</th>\n      <th>sinc3_3</th>\n      <th>intel3_3</th>\n      <th>fun3_3</th>\n      <th>amb3_3</th>\n      <th>attr5_3</th>\n      <th>sinc5_3</th>\n      <th>intel5_3</th>\n      <th>fun5_3</th>\n      <th>amb5_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>...</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8373</th>\n      <td>552</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>44</td>\n      <td>2</td>\n      <td>21</td>\n      <td>22</td>\n      <td>14</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>8374</th>\n      <td>552</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>44</td>\n      <td>2</td>\n      <td>21</td>\n      <td>22</td>\n      <td>13</td>\n      <td>10.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>8375</th>\n      <td>552</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>44</td>\n      <td>2</td>\n      <td>21</td>\n      <td>22</td>\n      <td>19</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>8376</th>\n      <td>552</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>44</td>\n      <td>2</td>\n      <td>21</td>\n      <td>22</td>\n      <td>3</td>\n      <td>10.0</td>\n      <td>16</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>8377</th>\n      <td>552</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>44</td>\n      <td>2</td>\n      <td>21</td>\n      <td>22</td>\n      <td>2</td>\n      <td>10.0</td>\n      <td>15</td>\n      <td>...</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8378 rows Ã— 195 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('..\\dataset\\Speed_Dating_Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(8378, 195)"
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "# Check for duplicate rows by using for the identifier columns (iid, id, partner, and pid)\n",
    "df.duplicated(subset=['iid', 'id', 'partner', 'pid']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "imprace\nmin: 0.0, max: 10.0\nimprelig\nmin: 1.0, max: 10.0\nsports\nmin: 1.0, max: 10.0\ntvsports\nmin: 1.0, max: 10.0\nexercise\nmin: 1.0, max: 10.0\ndining\nmin: 1.0, max: 10.0\nmuseums\nmin: 0.0, max: 10.0\nart\nmin: 0.0, max: 10.0\nhiking\nmin: 0.0, max: 10.0\ngaming\nmin: 0.0, max: 14.0\nclubbing\nmin: 0.0, max: 10.0\nreading\nmin: 1.0, max: 13.0\ntv\nmin: 1.0, max: 10.0\ntheater\nmin: 0.0, max: 10.0\nmovies\nmin: 0.0, max: 10.0\nconcerts\nmin: 0.0, max: 10.0\nmusic\nmin: 1.0, max: 10.0\nshopping\nmin: 1.0, max: 10.0\nyoga\nmin: 0.0, max: 10.0\n"
    }
   ],
   "source": [
    "# Check for unexpected values for the following numerical variables\n",
    "cols_to_check = ['imprace', 'imprelig', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga']\n",
    "for col in cols_to_check:\n",
    "    print(col)\n",
    "    print(f\"min: {df[col].min()}, max: {df[col].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the identified incorrect values\n",
    "# range should be between 1-10\n",
    "for col in cols_to_check:\n",
    "    df.loc[df[col] > 10, col] = 10\n",
    "    df.loc[df[col] < 10, col] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "imprace\nmin: 1.0, max: 10.0\nimprelig\nmin: 1.0, max: 10.0\nsports\nmin: 1.0, max: 10.0\ntvsports\nmin: 1.0, max: 10.0\nexercise\nmin: 1.0, max: 10.0\ndining\nmin: 1.0, max: 10.0\nmuseums\nmin: 1.0, max: 10.0\nart\nmin: 1.0, max: 10.0\nhiking\nmin: 1.0, max: 10.0\ngaming\nmin: 1.0, max: 10.0\nclubbing\nmin: 1.0, max: 10.0\nreading\nmin: 1.0, max: 10.0\ntv\nmin: 1.0, max: 10.0\ntheater\nmin: 1.0, max: 10.0\nmovies\nmin: 1.0, max: 10.0\nconcerts\nmin: 1.0, max: 10.0\nmusic\nmin: 1.0, max: 10.0\nshopping\nmin: 1.0, max: 10.0\nyoga\nmin: 1.0, max: 10.0\n"
    }
   ],
   "source": [
    "for col in cols_to_check:\n",
    "    print(col)\n",
    "    print(f\"min: {df[col].min()}, max: {df[col].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "iid           int64\nid          float64\ngender        int64\nidg           int64\ncondtn        int64\n             ...   \nattr5_3     float64\nsinc5_3     float64\nintel5_3    float64\nfun5_3      float64\namb5_3      float64\nLength: 195, dtype: object"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "# Check the data type\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "iid: int64\nid: float64\ngender: int64\nidg: int64\ncondtn: int64\nwave: int64\nround: int64\nposition: int64\npositin1: float64\norder: int64\npartner: int64\npid: float64\nmatch: int64\nint_corr: float64\nsamerace: int64\nage_o: float64\nrace_o: float64\npf_o_att: float64\npf_o_sin: float64\npf_o_int: float64\npf_o_fun: float64\npf_o_amb: float64\npf_o_sha: float64\ndec_o: int64\nattr_o: float64\nsinc_o: float64\nintel_o: float64\nfun_o: float64\namb_o: float64\nshar_o: float64\nlike_o: float64\nprob_o: float64\nmet_o: float64\nage: float64\nfield: object\nfield_cd: float64\nundergra: object\nmn_sat: float64\ntuition: float64\nrace: float64\nimprace: float64\nimprelig: float64\nfrom: object\nzipcode: float64\nincome: float64\ngoal: float64\ndate: float64\ngo_out: float64\ncareer: object\ncareer_c: float64\nsports: float64\ntvsports: float64\nexercise: float64\ndining: float64\nmuseums: float64\nart: float64\nhiking: float64\ngaming: float64\nclubbing: float64\nreading: float64\ntv: float64\ntheater: float64\nmovies: float64\nconcerts: float64\nmusic: float64\nshopping: float64\nyoga: float64\nexphappy: float64\nexpnum: float64\nattr1_1: float64\nsinc1_1: float64\nintel1_1: float64\nfun1_1: float64\namb1_1: float64\nshar1_1: float64\nattr4_1: float64\nsinc4_1: float64\nintel4_1: float64\nfun4_1: float64\namb4_1: float64\nshar4_1: float64\nattr2_1: float64\nsinc2_1: float64\nintel2_1: float64\nfun2_1: float64\namb2_1: float64\nshar2_1: float64\nattr3_1: float64\nsinc3_1: float64\nfun3_1: float64\nintel3_1: float64\namb3_1: float64\nattr5_1: float64\nsinc5_1: float64\nintel5_1: float64\nfun5_1: float64\namb5_1: float64\ndec: int64\nattr: float64\nsinc: float64\nintel: float64\nfun: float64\namb: float64\nshar: float64\nlike: float64\nprob: float64\nmet: float64\nmatch_es: float64\nattr1_s: float64\nsinc1_s: float64\nintel1_s: float64\nfun1_s: float64\namb1_s: float64\nshar1_s: float64\nattr3_s: float64\nsinc3_s: float64\nintel3_s: float64\nfun3_s: float64\namb3_s: float64\nsatis_2: float64\nlength: float64\nnumdat_2: float64\nattr7_2: float64\nsinc7_2: float64\nintel7_2: float64\nfun7_2: float64\namb7_2: float64\nshar7_2: float64\nattr1_2: float64\nsinc1_2: float64\nintel1_2: float64\nfun1_2: float64\namb1_2: float64\nshar1_2: float64\nattr4_2: float64\nsinc4_2: float64\nintel4_2: float64\nfun4_2: float64\namb4_2: float64\nshar4_2: float64\nattr2_2: float64\nsinc2_2: float64\nintel2_2: float64\nfun2_2: float64\namb2_2: float64\nshar2_2: float64\nattr3_2: float64\nsinc3_2: float64\nintel3_2: float64\nfun3_2: float64\namb3_2: float64\nattr5_2: float64\nsinc5_2: float64\nintel5_2: float64\nfun5_2: float64\namb5_2: float64\nyou_call: float64\nthem_cal: float64\ndate_3: float64\nnumdat_3: float64\nnum_in_3: float64\nattr1_3: float64\nsinc1_3: float64\nintel1_3: float64\nfun1_3: float64\namb1_3: float64\nshar1_3: float64\nattr7_3: float64\nsinc7_3: float64\nintel7_3: float64\nfun7_3: float64\namb7_3: float64\nshar7_3: float64\nattr4_3: float64\nsinc4_3: float64\nintel4_3: float64\nfun4_3: float64\namb4_3: float64\nshar4_3: float64\nattr2_3: float64\nsinc2_3: float64\nintel2_3: float64\nfun2_3: float64\namb2_3: float64\nshar2_3: float64\nattr3_3: float64\nsinc3_3: float64\nintel3_3: float64\nfun3_3: float64\namb3_3: float64\nattr5_3: float64\nsinc5_3: float64\nintel5_3: float64\nfun5_3: float64\namb5_3: float64\n"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['iid', 'id', 'gender', 'idg', 'condtn', 'wave', 'position', 'positin1',\n       'partner', 'pid',\n       ...\n       'attr3_3', 'sinc3_3', 'intel3_3', 'fun3_3', 'amb3_3', 'attr5_3',\n       'sinc5_3', 'intel5_3', 'fun5_3', 'amb5_3'],\n      dtype='object', length=188)"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "# Change the data types to categorical for the columns that don't contain numerical values\n",
    "num_cols = ['round', 'order', 'int_corr', 'age', 'mn_sat', 'income', 'expnum'] # numerical columns\n",
    "cat_cols = df.drop(num_cols, axis=1).columns\n",
    "cat_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "iid: category\nid: category\ngender: category\nidg: category\ncondtn: category\nwave: category\nround: int64\nposition: category\npositin1: category\norder: int64\npartner: category\npid: category\nmatch: category\nint_corr: float64\nsamerace: category\nage_o: category\nrace_o: category\npf_o_att: category\npf_o_sin: category\npf_o_int: category\npf_o_fun: category\npf_o_amb: category\npf_o_sha: category\ndec_o: category\nattr_o: category\nsinc_o: category\nintel_o: category\nfun_o: category\namb_o: category\nshar_o: category\nlike_o: category\nprob_o: category\nmet_o: category\nage: float64\nfield: category\nfield_cd: category\nundergra: category\nmn_sat: float64\ntuition: category\nrace: category\nimprace: category\nimprelig: category\nfrom: category\nzipcode: category\nincome: float64\ngoal: category\ndate: category\ngo_out: category\ncareer: category\ncareer_c: category\nsports: category\ntvsports: category\nexercise: category\ndining: category\nmuseums: category\nart: category\nhiking: category\ngaming: category\nclubbing: category\nreading: category\ntv: category\ntheater: category\nmovies: category\nconcerts: category\nmusic: category\nshopping: category\nyoga: category\nexphappy: category\nexpnum: float64\nattr1_1: category\nsinc1_1: category\nintel1_1: category\nfun1_1: category\namb1_1: category\nshar1_1: category\nattr4_1: category\nsinc4_1: category\nintel4_1: category\nfun4_1: category\namb4_1: category\nshar4_1: category\nattr2_1: category\nsinc2_1: category\nintel2_1: category\nfun2_1: category\namb2_1: category\nshar2_1: category\nattr3_1: category\nsinc3_1: category\nfun3_1: category\nintel3_1: category\namb3_1: category\nattr5_1: category\nsinc5_1: category\nintel5_1: category\nfun5_1: category\namb5_1: category\ndec: category\nattr: category\nsinc: category\nintel: category\nfun: category\namb: category\nshar: category\nlike: category\nprob: category\nmet: category\nmatch_es: category\nattr1_s: category\nsinc1_s: category\nintel1_s: category\nfun1_s: category\namb1_s: category\nshar1_s: category\nattr3_s: category\nsinc3_s: category\nintel3_s: category\nfun3_s: category\namb3_s: category\nsatis_2: category\nlength: category\nnumdat_2: category\nattr7_2: category\nsinc7_2: category\nintel7_2: category\nfun7_2: category\namb7_2: category\nshar7_2: category\nattr1_2: category\nsinc1_2: category\nintel1_2: category\nfun1_2: category\namb1_2: category\nshar1_2: category\nattr4_2: category\nsinc4_2: category\nintel4_2: category\nfun4_2: category\namb4_2: category\nshar4_2: category\nattr2_2: category\nsinc2_2: category\nintel2_2: category\nfun2_2: category\namb2_2: category\nshar2_2: category\nattr3_2: category\nsinc3_2: category\nintel3_2: category\nfun3_2: category\namb3_2: category\nattr5_2: category\nsinc5_2: category\nintel5_2: category\nfun5_2: category\namb5_2: category\nyou_call: category\nthem_cal: category\ndate_3: category\nnumdat_3: category\nnum_in_3: category\nattr1_3: category\nsinc1_3: category\nintel1_3: category\nfun1_3: category\namb1_3: category\nshar1_3: category\nattr7_3: category\nsinc7_3: category\nintel7_3: category\nfun7_3: category\namb7_3: category\nshar7_3: category\nattr4_3: category\nsinc4_3: category\nintel4_3: category\nfun4_3: category\namb4_3: category\nshar4_3: category\nattr2_3: category\nsinc2_3: category\nintel2_3: category\nfun2_3: category\namb2_3: category\nshar2_3: category\nattr3_3: category\nsinc3_3: category\nintel3_3: category\nfun3_3: category\namb3_3: category\nattr5_3: category\nsinc5_3: category\nintel5_3: category\nfun5_3: category\namb5_3: category\n"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "round          0\norder          0\nint_corr     158\nage           95\nmn_sat      5245\nincome      4099\nexpnum      6578\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "# Check for any missing values for each numerical variable\n",
    "df[num_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "round\n[10 16 19 18  5 20  9 21 14  8  6 11 15  7 22]\norder\n[ 4  3 10  5  7  6  1  2  8  9 11 15 12 16 13 14 18 17 19 20 21 22]\nint_corr\n[ 0.14  0.54  0.16  0.61  0.21  0.25  0.34  0.5   0.28 -0.36  0.29  0.18\n  0.1  -0.21  0.32  0.73  0.6   0.07  0.11  0.39 -0.24 -0.14  0.09 -0.04\n -0.3  -0.26 -0.15 -0.47 -0.18  0.05  0.37  0.35  0.15 -0.19 -0.43  0.\n -0.17  0.08 -0.16  0.06 -0.05 -0.13 -0.06  0.33 -0.51  0.12  0.19  0.47\n  0.03  0.46  0.43  0.52 -0.46 -0.27  0.59  0.31 -0.34 -0.03 -0.11  0.42\n -0.4  -0.23  0.17  0.68 -0.01 -0.35  0.3   0.65  0.24  0.41  0.49  0.01\n  0.22 -0.08  0.27  0.44  0.62 -0.2  -0.02 -0.33 -0.52 -0.1   0.58 -0.57\n -0.31 -0.07 -0.32  0.04 -0.12  0.48 -0.22 -0.29  0.38  0.53 -0.38  0.02\n -0.28  0.13  0.2    nan -0.41 -0.44  0.51 -0.48  0.4   0.26  0.77 -0.49\n -0.25 -0.09  0.45 -0.39  0.83  0.57 -0.61  0.72 -0.37  0.23 -0.58  0.8\n -0.56  0.63 -0.63  0.71  0.36  0.56  0.55  0.76  0.69  0.79  0.9   0.67\n  0.66  0.81  0.64  0.74  0.75  0.85 -0.42 -0.5  -0.59  0.7   0.82  0.78\n -0.45 -0.83  0.88 -0.7  -0.62 -0.55  0.87  0.91  0.84 -0.64 -0.73 -0.54]\nage\n[21. 24. 25. 23. 22. 26. 27. 30. 28. nan 29. 34. 35. 32. 39. 20. 19. 18.\n 37. 33. 36. 31. 42. 38. 55.]\nmn_sat\n[  nan 1070. 1258. 1400. 1290. 1460. 1430. 1215. 1330. 1450. 1155. 1140.\n 1360. 1402. 1250. 1210. 1220. 1410. 1260. 1380. 1030. 1309. 1308. 1050.\n 1100. 1310. 1490. 1188. 1097. 1212. 1340. 1034. 1185. 1242. 1160. 1099.\n 1214. 1270. 1110. 1178. 1060. 1157. 1180. 1014. 1341.  990. 1320. 1159.\n 1370. 1105. 1365. 1011. 1130. 1206. 1331. 1191.  914. 1200. 1080. 1090.\n 1092. 1470. 1149. 1134. 1230. 1267. 1280. 1227. 1239.]\nincome\n[ 69487.  65929.     nan  37754.  86340.  60304.  54620.  48652.  29237.\n  56580.  36782.  38548.  52010.  28418.  43185.  23152.  43664.  48441.\n  61152.  36485.  41507.  17134.  30038.  33772.  24997.  42096.  28891.\n  62635.  12063.  29809.  26482.  30147.  39919.  41466.  23988.  28989.\n  50948.  38022.  47559.  53539.  32159.  53940.  40753.  38207.  46166.\n  30973.  28317.  26645.  25589.  55223. 109031.  40409.  21597.  76624.\n  35968.  51725.  55419.  55550.  26682.  41547.  23361.  74893.  52804.\n  53923.  27094.  57213.  42390.  43636.  57887.  30768.  66699.  45360.\n  55080.  17378.  40375.  48929.  78193.  63351.  50745.  29279.  38774.\n  58802.  41831.  52186.  97857.  74624.  21590.  38832.  37248.  28240.\n  53771.  56096.  31560.  52467.  80006.  47572.  22439.  31383.  40749.\n  47997.  78704.  31143.  32129.  44195.  46837.  97972.  35960.  65708.\n  49466.  53229.  32649.  35867.  40244.  42640.  52388.  62875.  30855.\n  46800.  45695.  46792.  53501.  64716.  27248.  22805.  56118.  30146.\n  39123.  46153.  45300.  42397.  44346.  42225.  37405.  28524.  61141.\n   8607.  41476.  49841.  37240.  36594.  62997.  46608.  37881.  48944.\n  77112.  18283.  31432.  73073.  26706.  50060.  25401.  80608.  43844.\n  53196.  25786.  39394.  40695.  45788.  37315.  51663.  32563.  54303.\n  16908.  39729.  57316.  30587.  57513.  31857.  23207.  25831.  28759.\n  19264.  41778.  35963.  49409.  31516.  36223.  43367.  27503.  35187.\n  26298.  31148.  55704.  46138.  66827.  42897.  31809.  75347.  47005.\n  52805.  50725.  65693.  45736.  33906.  50501.  48785.  52318.  62844.\n  52586.  29236.  31486.  31632. 106663.  84043.  35224.  36381.  65498.\n  60000.  22669.  81266.  29746.  47556.  42651.  27794.  41737.  90225.\n  52280.  56056.  60835.  62829.  16767.  42967.  21488.  89977.  18619.\n  22161.  82734.  40163.  46185.  78844.  29575.  34752.  22173.  37994.\n  35409.  23707.  57501.  25314.  48876.  34870.  35848.  45017.  12416.\n  87789.  50572.  49642.  20000.  32508.  35627.  46280.  41191.  71787.\n  72412.  36510.  32386.  15863.  46272.  48137.  61686.  47624.  36673.\n  55138.]\nexpnum\n[ 2.  5. 10.  3. 15. 20.  4.  9. 19.  0. nan  8. 12.  1.  7.  6. 18. 14.\n 13.]\n"
    }
   ],
   "source": [
    "# Replace the missing values for each numerical variable with their corresponding mean or median\n",
    "for col in num_cols:\n",
    "    print(col)\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values of the int_corr column range between -1 and 1. It seems like they have been normalized. \n",
    "# Since there are no extreme values or outliers, you can impute the missing values with the mean of this variable.\n",
    "m = df['int_corr'].median()\n",
    "df['int_corr'].fillna(m, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other columns haven't been normalized and some of them have outliers. \n",
    "# This time, you are going to need to use their medians to fill in the missing values.\n",
    "missing_num_cols = ['age', 'mn_sat', 'income', 'expnum']\n",
    "for col in missing_num_cols :\n",
    "    m = df[col].median()\n",
    "    df[col].fillna(m, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "round       0\norder       0\nint_corr    0\nage         0\nmn_sat      0\nincome      0\nexpnum      0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "df[num_cols].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}