{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.2 64-bit ('dsw')",
   "display_name": "Python 3.7.2 64-bit ('dsw')",
   "metadata": {
    "interpreter": {
     "hash": "0d469a86b9a09f89c1759d071d50989ca98f9a2423bcdef283c9e386d614e982"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Complete ML Workflow in a Pipeline\n",
    "\n",
    "You are working as a data scientist at a heart clinic. You have been assigned the task of doing an initial screening of patients based on their body parameters, such as cholesterol, blood pressure, pulse, and more.\n",
    "\n",
    "The aim of this activity is for you to predict whether a patient has a heart ailment using the patient parameters' dataset. To make the data science life cycle simple, you will be using an ML pipeline for this project as you have done elsewhere in this chapter.\n",
    "\n",
    "---\n",
    "\n",
    "So far in this chapter, we have seen different examples of how ML pipelines could be put to use progressively to automate the data science life cycle. It is now time to apply our learning to a new dataset.\n",
    "\n",
    "We will be using a heart disease prediction dataset that is available courtesy of the UCI Machine Learning Repository. The dataset is called processed.cleveland.data.\n",
    "\n",
    "This dataset contains around 14 attributes related to parameters of the body, such as cholesterol, blood pressure, the presence of chest pain, and more, that could be an indicator of heart disease. In addition to these body parameters, there are also person-specific details, such as age and sex. The problem statement is to predict whether there is a possibility of heart disease. To find out more about the attributes of the dataset, you can make use of this [link](https://github.com/PacktWorkshops/The-Data-Science-Workshop/blob/master/Chapter16/Dataset/heart-disease.names).\n",
    "\n",
    "The target variable has different classes ranging from 0 to 4. Class 0 means no heart disease, and classes 1 to 4 indicate the presence of heart disease.\n",
    "\n",
    "In the upcoming activity, we will convert the problem into a binary classification problem, to make the problem statement simple. So, we would be predicting whether there is a heart ailment or not. This entails transforming the classes of the target variable to just 0 and 1. The existing 0 class will remain as it is, and classes 1 to 4 will have to be mapped to class 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n\n     slope   ca  thal  label  \n0      3.0  0.0   6.0      0  \n1      2.0  3.0   3.0      2  \n2      2.0  2.0   7.0      1  \n3      3.0  0.0   3.0      0  \n4      1.0  0.0   3.0      0  \n..     ...  ...   ...    ...  \n298    2.0  0.0   7.0      1  \n299    2.0  2.0   7.0      2  \n300    2.0  1.0   7.0      3  \n301    2.0  1.0   3.0      1  \n302    1.0  NaN   3.0      0  \n\n[303 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>2.3</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>108.0</td>\n      <td>1.0</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>129.0</td>\n      <td>1.0</td>\n      <td>2.6</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>187.0</td>\n      <td>0.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n      <td>204.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>172.0</td>\n      <td>0.0</td>\n      <td>1.4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>45.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>110.0</td>\n      <td>264.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>132.0</td>\n      <td>0.0</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>68.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>144.0</td>\n      <td>193.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>141.0</td>\n      <td>0.0</td>\n      <td>3.4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>130.0</td>\n      <td>131.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>115.0</td>\n      <td>1.0</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n      <td>236.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>174.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>38.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>138.0</td>\n      <td>175.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>173.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 14 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "df = pd.read_csv('../Dataset/processed.cleveland.data', sep=',', header=None, na_values='?')\n",
    "df.columns = ['age','sex', 'cp', 'trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','label']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n\n     slope   ca  thal  label  \n0      3.0  0.0   6.0      0  \n1      2.0  3.0   3.0      1  \n2      2.0  2.0   7.0      1  \n3      3.0  0.0   3.0      0  \n4      1.0  0.0   3.0      0  \n..     ...  ...   ...    ...  \n298    2.0  0.0   7.0      1  \n299    2.0  2.0   7.0      1  \n300    2.0  1.0   7.0      1  \n301    2.0  1.0   3.0      1  \n302    1.0  NaN   3.0      0  \n\n[303 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>2.3</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>108.0</td>\n      <td>1.0</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>129.0</td>\n      <td>1.0</td>\n      <td>2.6</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>187.0</td>\n      <td>0.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n      <td>204.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>172.0</td>\n      <td>0.0</td>\n      <td>1.4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>45.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>110.0</td>\n      <td>264.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>132.0</td>\n      <td>0.0</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>68.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>144.0</td>\n      <td>193.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>141.0</td>\n      <td>0.0</td>\n      <td>3.4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>130.0</td>\n      <td>131.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>115.0</td>\n      <td>1.0</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n      <td>236.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>174.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>38.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>138.0</td>\n      <td>175.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>173.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 14 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# Change the classes of all values other than 0 in the label column to 1\n",
    "df.loc[df['label'] > 0, 'label'] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n297  57.0  0.0  4.0     140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n\n     slope   ca  thal  label  \n0      3.0  0.0   6.0      0  \n1      2.0  3.0   3.0      1  \n2      2.0  2.0   7.0      1  \n3      3.0  0.0   3.0      0  \n4      1.0  0.0   3.0      0  \n..     ...  ...   ...    ...  \n297    2.0  0.0   7.0      1  \n298    2.0  0.0   7.0      1  \n299    2.0  2.0   7.0      1  \n300    2.0  1.0   7.0      1  \n301    2.0  1.0   3.0      1  \n\n[297 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>2.3</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>108.0</td>\n      <td>1.0</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>129.0</td>\n      <td>1.0</td>\n      <td>2.6</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>187.0</td>\n      <td>0.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n      <td>204.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>172.0</td>\n      <td>0.0</td>\n      <td>1.4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>140.0</td>\n      <td>241.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>123.0</td>\n      <td>1.0</td>\n      <td>0.2</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>45.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>110.0</td>\n      <td>264.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>132.0</td>\n      <td>0.0</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>68.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>144.0</td>\n      <td>193.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>141.0</td>\n      <td>0.0</td>\n      <td>3.4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>57.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>130.0</td>\n      <td>131.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>115.0</td>\n      <td>1.0</td>\n      <td>1.2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>130.0</td>\n      <td>236.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>174.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>297 rows × 14 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Drop all NA values\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "catColumns = ['restecg', 'slope', 'thal']\n",
    "for col in catColumns:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "age          float64\nsex          float64\ncp           float64\ntrestbps     float64\nchol         float64\nfbs          float64\nrestecg     category\nthalach      float64\nexang        float64\noldpeak      float64\nslope       category\nca           float64\nthal        category\nlabel          int64\ndtype: object"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X, y variables\n",
    "y = df.pop('label')\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(207, 13)\n(90, 13)\n(207,)\n(90,)\n"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Create preprocessor\n",
    "###########################\n",
    "\n",
    "# Pipeline for transforming categorical variables\n",
    "catTransformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "catFeatures = X_train.select_dtypes(include=['category']).columns\n",
    "# Pipeline for scaling numerical variables\n",
    "numTransformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "numFeatures = X_train.select_dtypes(include=['float64']).columns\n",
    "\n",
    "# Create the preprocessing engine\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numTransformer, numFeatures),\n",
    "        ('categoric', catTransformer, catFeatures)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "KNeighborsClassifier()\nmodel score: 0.76\nRandomForestClassifier(random_state=123)\nmodel score: 0.84\nAdaBoostClassifier(random_state=123)\nmodel score: 0.77\nLogisticRegression(random_state=123)\nmodel score: 0.78\n"
    }
   ],
   "source": [
    "###############################\n",
    "# Create engine for spot-check\n",
    "###############################\n",
    "\n",
    "# Create a list of the classifiers\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),     \n",
    "    RandomForestClassifier(random_state=123),\n",
    "    AdaBoostClassifier(random_state=123),\n",
    "    LogisticRegression(random_state=123)\n",
    "]\n",
    "\n",
    "# iterate classifiers\n",
    "for classifier in classifiers:\n",
    "    estimator = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('dimred', PCA(10)),\n",
    "            ('classifier', classifier)\n",
    "        ]\n",
    "    )\n",
    "    estimator.fit(X_train, y_train)   \n",
    "    print(classifier)\n",
    "    print(\"model score: %.2f\" % estimator.score(X_test, y_test))"
   ]
  },
  {
   "source": [
    "### Select the model that generates the highest accuracy score for grid search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline with RandomForestClassifier\n",
    "pipe = Pipeline(\n",
    "     steps=[\n",
    "          ('preprocessor', preprocessor),\n",
    "          ('dimred', PCA()),\n",
    "          ('classifier',RandomForestClassifier(random_state=123))\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=10,\n             estimator=Pipeline(steps=[('preprocessor',\n                                        ColumnTransformer(transformers=[('numeric',\n                                                                         Pipeline(steps=[('scaler',\n                                                                                          StandardScaler())]),\n                                                                         Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'thalach', 'exang',\n       'oldpeak', 'ca'],\n      dtype='object')),\n                                                                        ('categoric',\n                                                                         Pipeline(steps=[('onehot',\n                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n                                                                         Index(['restecg', 'slope', 'thal'], dtype='object'))])),\n                                       ('dimred', PCA()),\n                                       ('classifier',\n                                        RandomForestClassifier(random_state=123))]),\n             param_grid={'classifier__n_estimators': [50, 100, 200],\n                         'dimred__n_components': [10, 11, 12, 13]})"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# Defining the parameters as a dictionary\n",
    "param_grid = {\n",
    "    'dimred__n_components': [10, 11, 12, 13],\n",
    "    'classifier__n_estimators': [50, 100, 200]\n",
    "}\n",
    "# Fitting the grid search\n",
    "estimator = GridSearchCV(pipe, cv=10, param_grid=param_grid)\n",
    "# Fitting the estimator on the training set\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best: 0.8411904761904762 using {'classifier__n_estimators': 50, 'dimred__n_components': 10}\n"
    }
   ],
   "source": [
    "# Printing the best score and best parameters\n",
    "print(f\"Best: {estimator.best_score_} using {estimator.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting with the best estimator\n",
    "y_pred = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[43  6]\n [ 8 33]]\n\n\n              precision    recall  f1-score   support\n\n           0       0.84      0.88      0.86        49\n           1       0.85      0.80      0.83        41\n\n    accuracy                           0.84        90\n   macro avg       0.84      0.84      0.84        90\nweighted avg       0.84      0.84      0.84        90\n\n"
    }
   ],
   "source": [
    "# Evaluate\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}